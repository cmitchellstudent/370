{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Sentiment Analysis \n",
    "these first few blocks are me copy-pasting the https://realpython.com/python-nltk-sentiment-analysis/#using-nltks-pre-trained-sentiment-analyzer \n",
    "code and learning how it works"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b10a00a8c0979664"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-09T04:35:46.138230100Z",
     "start_time": "2024-04-09T04:35:46.109940700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.8012}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(\"Wow, NLTK is really powerful!\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tweets = [t.replace(\"://\", \"//\") for t in nltk.corpus.twitter_samples.strings()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T04:35:47.818861300Z",
     "start_time": "2024-04-09T04:35:46.120213900Z"
    }
   },
   "id": "22da11d57ed0e665",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> False @Clarrknulp I don't get your point. Are there Labour voters in Scotland who will be annoyed if Miliband doesn't do a deal with the SNP?\n",
      "> True @josielong Don't panic.  My take: https//t.co/eeAxt0ZSLu.  Caroline Flint confirms it here: http//t.co/IG5OkrHtt1\n",
      "> False @DeborahJaneOrr @DaAwob don't think many safe Labour seats left in my part of the woods. #snp\n",
      "> True @RorkesDrift2 @mrmarksteel yet it's ok for Scotland to return 1 Tory MP, and get a Tory govt ?\n",
      "> False RT @NickServini: .@welshlabour say tonight all of the comments from @Ed_Miliband in relation to the SNP apply to Plaid in exactly the same â€¦\n",
      "> False RT @WingsScotland: Be interesting to see what the papers report tomorrow. Miliband actually said nothing new, just worded something badly tâ€¦\n",
      "> False RT @JeremyJHardy: The good thing about election time is the Tories work overtime to remind you they are horrible scum\n",
      "> False @brittleyouth @Tom_J_Allen @AndrewFairbairn @batemanesque @Hegelbon @jameswheeler that was the worst part and I still feel bad about it :(\n",
      "> False If you refer to the leaders of the Tories, Labour and Lib Dems as \"the three amigos\" you need to get a grip of yourself\n",
      "> False @TheHinduTheatre @evam_entd Why no Bangalore? :(\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def is_positive(tweet: str) -> bool:\n",
    "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
    "    return sia.polarity_scores(tweet)[\"compound\"] > 0\n",
    "\n",
    "shuffle(tweets)\n",
    "for tweet in tweets[:10]:\n",
    "    print(\">\", is_positive(tweet), tweet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T04:35:47.837382100Z",
     "start_time": "2024-04-09T04:35:47.821864300Z"
    }
   },
   "id": "a43edf21a1ca9997",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "## my turn\n",
    "Doing the same as above, but now with my corpus instead of tweets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9c9f8be190822bb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I highly recommend everyone get drunk with friends and watch this     ', \"My introduction to John cena's absolutely delicious looking biceps     \", 'Not fast enough!     ', ' On march 24th 2023 Kanye West said he is no longer anti semitic because of this movie and Jonah Hill     ', \"Why are old people having fun they're literally gonna die tomorrow ðŸ˜­     \", 'Kids movie where dolls fight for their lives after the world ends in a terrifying way   somehow still less scary than happy feet     ', 'Yeah my ass was crying again my ass is always crying     ', 'Worst theater experience of my life fun movie tho     ', 'Wow wow wow wow wow WOW     ', ' Severe lack of solar systems but overall a good time     ']\n"
     ]
    }
   ],
   "source": [
    "#corpus as list of strings\n",
    "import pandas as pd\n",
    "df = pd.read_csv('C:\\\\Users\\Connor\\Desktop\\\\370\\letterboxdCorpus\\\\all.csv')\n",
    "reviews = df.reviews.tolist()\n",
    "scoreless = []\n",
    "for review in reviews:\n",
    "    scoreless.append(review[5:])\n",
    "print(scoreless[0:10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T04:35:47.931948400Z",
     "start_time": "2024-04-09T04:35:47.837382100Z"
    }
   },
   "id": "84a9143414323b78",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> True can't decide if that tech dude's mansion would be a good place to be quarantined or a terrifying / desolate / super drafty place to be quarantined. although at this point i'm starting to feel like *any* house â€” even the kind of desolate cliffside fortress that 's basically just what a billionaire tech bro might design after watching HEAT once â€” would be nice to be stuck inside these days. at least my son can't crawl yet. and my...     \n",
      "> True  really quietly affecting work from my dear friend jacob. this one is introspective and soft, and definitely his most mature short film yet. a muted look at the way people drift in and out of our lives, and how sometimes they're called back to our minds even if we haven't thought about them for a while. and i was lucky to be an advising editor and help out with the poster as well, it brings me immense joy and pride to see jacob's work come to life every time. you can watch the short film here     \n",
      "> True I am so not the target audience for this movie. I liked it anyway.  Full review: screencrush.com/how-to-be-single-review/     \n",
      "> False contrary to popular belief, brian de palma's greatest contribution to the art of cinema was not the prom scene from Carrie, but his casting of john cassavetes as an evil fbi agent who wears a singular black glove     \n",
      "> True nice and festive :)     \n",
      "> True Will you like ENTOURAGE? That depends. Did you like ENTOURAGE on television but wish there were more graphic sex scenes that involved Kevin Connolly? Then, yes, you will like ENTOURAGE. Do you prefer movies that are even the slightest bit cinematic and feature characters that evolve and feel and do dramatic things and aren't just conveyances for guest stars, frat boy put-downs, and Cadillac product placement? Then, no, you will not like ENTOURAGE.  Full review: screencrush.com/entourage-review/     \n",
      "> False netflix: waste our subscribers time 2k18     \n",
      "> False everyone leaving margaret qualley on earth by herself? idk it just doesn't seem realistic to me i would never do that     \n",
      "> True \"are you sure that's what you want?\"  emily watson gives a stellar and unique performance, but otherwise this only just held my attention. recently my fascination with how lars lays out his morbid stories keep me invested in them, but here that seems to fall short. there's always a generous amount of anguish, but it felt less affecting and the ending less meaningful here. almost pointless. he's a mess and a hot pile of garbage as a person anyways, but...     \n",
      "> False possibly the wettest version of gotham     \n"
     ]
    }
   ],
   "source": [
    "shuffle(scoreless)\n",
    "for review in scoreless[:10]:\n",
    "    print(\">\", is_positive(review), review)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T04:35:47.948963900Z",
     "start_time": "2024-04-09T04:35:47.930947500Z"
    }
   },
   "id": "19a961be0aa6f45e",
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "I honestly don't mind the supposed ~60% accuracy. I do like the results."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bfb09064667cc06"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## generating top 100s"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da607beacd76729b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "unwanted = nltk.corpus.stopwords.words(\"english\")\n",
    "unwanted.extend([w.lower() for w in nltk.corpus.names.words()])\n",
    "#\n",
    "#here's my own injection, which makes a list of words in positive reviews and a list\n",
    "#of negative reviews, so that I don't need to use the nltk.corpus movie reviews\n",
    "pos_category = []\n",
    "neg_category = []\n",
    "for review in scoreless:\n",
    "    words = review.split()\n",
    "    if is_positive(review): \n",
    "        for word in words:\n",
    "            pos_category.append(word)\n",
    "    else:\n",
    "        for word in words:\n",
    "            neg_category.append(word)\n",
    "\n",
    "\n",
    "def skip_unwanted(pos_tuple):\n",
    "    word, tag = pos_tuple\n",
    "    if not word.isalpha() or word in unwanted:\n",
    "        return False\n",
    "    if tag.startswith(\"NN\"):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "#here's where it trains off my stuff rather than nltk movie reviews\n",
    "positive_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(pos_category)\n",
    ")]\n",
    "negative_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(neg_category)\n",
    ")]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T04:37:06.453789400Z",
     "start_time": "2024-04-09T04:35:47.949965500Z"
    }
   },
   "id": "9da16cc4dbf8dcdf",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSTIVE:\n",
      "{'satisfied', 'owning', 'prominent', 'thankful', 'kissing', 'joyful', 'easiest', 'inspirational', 'subscribing', 'cutest', 'Subscribing', 'beguiling', 'delighted', 'breathlessly', 'hopeful', 'Liked', 'owed', 'costuming', 'intelligent', 'thrilled', 'stultifying', 'approach', 'mined', 'curly', 'superb', 'sharply', 'lovelorn', 'obscure', 'pls', 'ground', 'inclusive', 'hong', 'saturday', 'riotous', 'subverts', 'pleasantly', 'remained', 'richly', 'celebrate', 'impoverished', 'blessed', 'harmless', 'minding', 'emerges', 'improvisational', 'entered', 'united', 'documented', 'WANT', 'rebellious', 'kidding', 'uncharted', 'smile', 'Essentially', 'extend', 'hagiographic', 'perceive', 'eps', 'gain', 'transcends', 'grateful', 'cringe', 'breakout', 'panoramic', 'libertarian', 'vibe', 'smooth', 'luckily', 'mandatory', 'seamless', 'Preparing', 'table', 'underwhelming', 'enthusiastic', 'captivated', 'sporadically', 'insistently', 'subconsciously', 'award', 'sugary', 'contemplative', 'intricately', 'credits', 'maniacal', 'bat', 'euphoric', 'sweetie', 'breezy', 'tweeted', 'automatic', 'microcosmic', 'undervalued', 'exploded', 'pleasing', 'delight', 'flip', 'ranked', 'treasure', 'eagerly', 'ecstatically'}\n",
      "NEGATIVE:\n",
      "{'yersel', 'uh', 'scumbag', 'deakins', 'lock', 'illuminates', 'Along', 'springs', 'smug', 'plan', 'nah', 'bury', 'choke', 'repulsed', 'posed', 'torture', 'anguish', 'assaulted', 'farcically', 'fatally', 'petrified', 'jingoistic', 'willingly', 'answers', 'harvest', 'scathing', 'animalistic', 'confounding', 'blindly', 'freewheeling', 'confronts', 'nope', 'timothÃ©e', 'Appropriately', 'flagrantly', 'excruciatingly', 'shoving', 'earning', 'identifies', 'mulleted', 'mangled', 'pickup', 'prom', 'tighten', 'revisionist', 'bafflingly', 'patently', 'armiesToo', 'dehumanizing', 'tryna', 'violates', 'exhilaratingly', 'sturdily', 'amnesiac', 'performs', 'punish', 'bums', 'placid', 'lousy', 'ooky', 'buys', 'suicidal', 'artless', 'gaslight', 'pioneering', 'meaningless', 'disfigured', 'stream', 'trembling', 'GOT', 'crawl', 'hairy', 'systematic', 'opting', 'external', 'lure', 'blaxplo', 'bitterly', 'babe', 'assaultive', 'Violent', 'disrespected', 'juxtaposed', 'reverberating', 'discussed', 'collapses', 'unmotivated', 'hunted', 'enamored', 'reported', 'abducted', 'respond', 'sift', 'regrettably', 'uptight', 'scarred', 'Basically', 'Spends', 'sob', 'leering'}\n"
     ]
    }
   ],
   "source": [
    "positive_fd = nltk.FreqDist(positive_words)\n",
    "negative_fd = nltk.FreqDist(negative_words)\n",
    "\n",
    "common_set = set(positive_fd).intersection(negative_fd)\n",
    "\n",
    "for word in common_set:\n",
    "    del positive_fd[word]\n",
    "    del negative_fd[word]\n",
    "\n",
    "top_100_positive = {word for word, count in positive_fd.most_common(100)}\n",
    "top_100_negative = {word for word, count in negative_fd.most_common(100)}\n",
    "print(\"POSTIVE:\")\n",
    "print(top_100_positive)\n",
    "print(\"NEGATIVE:\")\n",
    "print(top_100_negative)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T04:37:06.587820300Z",
     "start_time": "2024-04-09T04:37:06.455791900Z"
    }
   },
   "id": "f1254a2eb71ff700",
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, there are the rough top 100 positive and negative words in my corpus. Apart from a few questionable results here and there, I'd consider it mostly good."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edc27ef32a459070"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's an idea. I'm going to redefine my pos/neg_category variables using the user scores attached to reviews. I'm hoping it gives me more accurate evaluations than the polarity scores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8860e410e602db4e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'highly', 'recommend', 'everyone', 'get', 'drunk', 'with', 'friends', 'and', 'watch', 'this', 'my', 'introduction', 'to', 'john', 'cena', \"'s\", 'absolutely', 'delicious', 'looking', 'biceps', 'i', 'like', 'that', 'one', 'robert', 'de', 'niro', 'comedy', 'where', 'he', 'shows', 'his', 'cock', 'and', 'fucks', 'like', 'crazy', 'this', 'is', 'not', 'that', 'one', 'tho', 'i', 'know', 'a', 'guy', 'named', 'aksel']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#8s, 9s, and 10/10s\n",
    "good_movies = []\n",
    "#3s, 2s, and 1/10s\n",
    "bad_movies = []\n",
    "#var for later\n",
    "sentences = []\n",
    "for review in reviews:\n",
    "    if review.startswith(\"10\") or review.startswith(\"9\") or review.startswith(\"8\"):\n",
    "        lower = review[5:].lower()\n",
    "        tokens = word_tokenize(lower)\n",
    "        for token in tokens:\n",
    "            good_movies.append(token)\n",
    "    if review.startswith(\"1/\") or review.startswith(\"2\") or review.startswith(\"3\"):\n",
    "        lower = review[5:].lower()\n",
    "        tokens = word_tokenize(lower)\n",
    "        for token in tokens:\n",
    "            bad_movies.append(token)\n",
    "    lower2 = review[5:].lower()\n",
    "    tokens2 = word_tokenize(lower2)\n",
    "    sentences.append(tokens2)\n",
    "print(bad_movies[0:50])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T04:37:14.524435900Z",
     "start_time": "2024-04-09T04:37:06.586819600Z"
    }
   },
   "id": "dce4b857be449232",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "I'm too lazy to go up and make a function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0b65c9f8aac0718"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSTIVE:\n",
      "{'allows', 'bodily', 'subscribing', 'gothic', 'inherent', 'grounded', 'vivid', 'detailed', 'stronger', 'scariest', 'warm', 'devastating', 'empathetic', 'tiny', 'noir', 'moves', 'masterful', 'vital', 'sudden', 'ep', 'fantastical', 'adds', 'trapped', 'rewatch', 'pulls', 'grew', 'shaking', 'gleefully', 'tense', 'internal', 'sees', 'wrapped', 'neon', 'delicate', 'exquisite', 'twin', 'sensual', 'familial', 'experimental', 'atmosphere', 'marvelous', 'loving', 'elegant', 'gorgeously', 'builds', 'detective', 'apocalyptic', 'melancholic', 'lying', 'expertly', 'harsh', 'layered', 'harrowing', 'claustrophobic', 'flawed', 'grateful', 'ghostly', 'phenomenal', 'indelible', 'fitting', 'finds', 'hysterical', 'showcasing', 'unexpected', 'surreal', 'uses', 'magnificent', 'underrated', 'breaking', 'nightmarish', 'shown', 'similar', 'touching', 'essential', 'dreamy', 'vividly', 'classical', 'gentle', 'allow', 'adding', 'fractured', 'vicious', 'beautifully', 'flows', 'existential', 'impeccable', 'terrified', 'subtle', 'operating', 'hearing', 'revolutionary', 'tight', 'elemental', 'experience', 'thrilling', 'captures', 'nonetheless', 'abstract', 'intimate', 'invented'}\n",
      "NEGATIVE:\n",
      "{'telegraphed', 'wringing', 'interchangeable', 'smug', 'rank', 'extraneous', 'hbo', 'elephant', 'dinesh', 'bedazzled', 'cw', 'aspires', 'guessing', 'unmitigated', 'counterfeit', 'redeemed', 'inconceivable', 'discernible', 'trolling', 'lucrative', 'tattoo', 'benign', 'unsolicited', 'insipid', 'fatally', 'dilutes', 'willingly', 'legs', 'cutesy', 'upgrade', 'inert', 'falsely', 'flatulent', 'cribbed', 'asexual', 'neeson', 'limp', 'pains', 'factual', 'steaming', 'metric', 'asinine', 'flavorless', 'forehead', 'paired', 'mistakes', 'digitally', 'resurrect', 'oppressively', 'foaming', 'downhill', 'regurgitating', 'fuckahhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhfuck', 'haphazardly', 'apocryphal', 'prosthetic', 'kooky', 'squanders', 'artless', 'crap', 'recycling', 'artemis', 'japan', 'contend', 'conspicuous', 'misleading', 'unexciting', 'bland', 'laziest', 'barring', 'orientalist', 'comped', 'wastes', 'adequate', 'prevent', 'glorified', 'smugly', 'careless', 'faintest', 'greenscreen', 'abysmal', 'phenomenally', 'vacuous', 'ass', 'aping', 'insufferably', 'gong', 'yall', 'wadlow', 'weakened', 'twist', 'finance', 'lifeless', 'clueless', 'tarnish', 'ought', 'slapdash', 'redefine', 'lame', 'contrary'}\n"
     ]
    }
   ],
   "source": [
    "#now processing new stuff see line 4 and 8\n",
    "positive_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(good_movies)\n",
    ")]\n",
    "negative_words = [word for word, tag in filter(\n",
    "    skip_unwanted,\n",
    "    nltk.pos_tag(bad_movies)\n",
    ")]\n",
    "positive_fd = nltk.FreqDist(positive_words)\n",
    "negative_fd = nltk.FreqDist(negative_words)\n",
    "\n",
    "common_set = set(positive_fd).intersection(negative_fd)\n",
    "\n",
    "for word in common_set:\n",
    "    del positive_fd[word]\n",
    "    del negative_fd[word]\n",
    "\n",
    "top_100_positive = {word for word, count in positive_fd.most_common(100)}\n",
    "top_100_negative = {word for word, count in negative_fd.most_common(100)}\n",
    "print(\"POSTIVE:\")\n",
    "print(top_100_positive)\n",
    "print(\"NEGATIVE:\")\n",
    "print(top_100_negative)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T04:37:49.520176200Z",
     "start_time": "2024-04-09T04:37:14.523435400Z"
    }
   },
   "id": "38ab2b350803b620",
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": [
    "Even cooler results. Although maybe affected by a smaller sample size, since I'm seeing the infrequently used \"fuckahhhhhhhhh\" in the negative.\n",
    "\n",
    "So my best idea to find more stuff with word embeddings is to process my positive and negative words and see what pops up frequently in .most_similar calls"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d7f57c52535d10d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25344\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "print(len(sentences))\n",
    "model = Word2Vec(sentences = sentences,\n",
    "                 window = 2, \n",
    "                 min_count =1,\n",
    "                 vector_size = 5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T04:37:51.533129800Z",
     "start_time": "2024-04-09T04:37:49.516172800Z"
    }
   },
   "id": "91956735a39ce755",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORDS \"SIMILAR TO\" POSITIVE WORDS:\n",
      "possessed:24  mania:24  ludicrous:24  intense:24  lego:24  gimmick:23  unexpectedly:23  comedies:23  tj:23  opens:23  setting:23  convoluted:23  deadly:23  vigilante:22  artificial:22  sustained:22  tissue:22  rhythms:22  shark:22  thrills:22  soft:22  chase:22  lush:22  junk:22  casual:22  absurdly:22  overlong:22  quiet:22  fits:22  fat:22  questioning:21  lil:21  madman:21  misery:21  variety:21  fractured:21  develops:21  grisly:21  coda:21  awkwardness:21  stretched:21  delightfully:21  hypnotic:21  messy:21  60s:21  aesthetic:21  gag:21  sincere:21  subverts:21  unhinged:21  row:21  apocalypse:21  holiday:21  melancholy:21  source:21  macho:21  tragic:21  clean:21  suggesting:21  rendered:21  aces:21  bland:21  tantalizing:21  jagged:21  pov:20  crossfire:20  stunt:20  lengthy:20  surfaces:20  moody:20  drug:20  pop:20  locations:20  troop:20  drenched:20  absent:20  underneath:20  bloody:20  analog:20  hayley:20  occasional:20  grieving:20  tremendous:20  60:20  exposition:20  christ-like:20  caper:20  liberation:20  sticky:20  alien:20  ex-soviet:20  expression:20  sadness:20  spectacle:20  faithful:20  eminent:20  provocative:20  mediocre:20  devastating:20  highlights:20  faye:20  hyper-accomplished:20  effortlessly:20  morally:20  bending:20  ultimate:20  twisted:20  progressive:20  sober:20  nonsensical:20  radical:20  cowardice:20  suggests:20  uplifting:20  cranked:20  standout:20  ring:20  puppet:20  lady:20  explicit:19  patience:19  erotic:19  thematically:19  tranquil:19  criminal:19  gangster:19  cgi:19  steam:19  forms:19  autumn:19  sims:19  psychedelic:19  argento:19  immaculate:19  sensitive:19  equal:19  adventure:19  flynn:19  class-divided:19  witty:19  dedicated:19  vicious:19  incoherent:19  astonishing:19  depicting:19  campfire:19  laurent:19  sets:19  intensely:19  hysterical:19  detective:19  tonally:19  horrendous:19  captivating:19  achievement:19  unnecessary:19  vital:19  trilogy:19  mainly:19  nonsense:19  drained:19  deliriously:19  mesmerizing:19  cutting:19  unexpected:19  equally:19  utterly:19  universal:19  advertising:19  bags:19  cheap-looking:19  artist:19  refreshingly:19  corruption:18  regional:18  akira:18  clown:18  diverse:18  terse:18  stumbles:18  twomey:18  economic:18  courtroom:18  angst:18  drone:18  vast:18  post-war:18  former:18  satirical:18  reflected:18  political:18  creating:18  cynical:18  shoe:18  office:18  tacky:18  unreconstructed:18  plotting:18  india:18  ghost:18  \n"
     ]
    }
   ],
   "source": [
    "#similar_words = model.wv.most_similar('sensual', topn= 10)\n",
    "# ^ list of tuples. first word = [0][0]\n",
    "#making a dictionary in the (word, count) format\n",
    "near_positive = {}\n",
    "for word in top_100_positive:\n",
    "    sim = model.wv.most_similar(word, topn= 500)\n",
    "    for i in range(500):\n",
    "        synonym = sim[i][0]\n",
    "        #print(word)\n",
    "        if synonym in near_positive:\n",
    "            near_positive[synonym] += 1\n",
    "        else:\n",
    "            near_positive[synonym] = 1\n",
    "sorted_pos = {k: v for k, v in sorted(near_positive.items(), key=lambda item: item[1], reverse=True)}\n",
    "print(\"WORDS \\\"SIMILAR TO\\\" POSITIVE WORDS:\")\n",
    "message = \"\"\n",
    "for key, value in list(sorted_pos.items())[:200]:\n",
    "    message += f\"{key}:{value}  \"\n",
    "print(message)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T04:37:51.626619200Z",
     "start_time": "2024-04-09T04:37:51.536132500Z"
    }
   },
   "id": "8fe4ef81a4fc45d2",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORDS \"SIMILAR TO\" NEGATIVE WORDS:\n",
      "forbidden:9  2022-2023:9  plotline:9  narcissists:9  flick:8  amounts:8  sporadically:8  deserved:8  embodiment:8  regrettably:8  hillary:8  accurately:8  moods:8  dunhills:8  bubble-blowing:8  wrote:8  glue:8  panic:8  scares:8  places:8  whodunnit:8  cave:8  knight:8  semi-realism:8  woven:8  tune:8  shorts:8  factor:8  sov:7  jesse:7  kingdom:7  showcasing:7  demonic:7  misogynist:7  anthony:7  creatures:7  pool:7  skills:7  quote:7  attendant:7  parker:7  kidnapping:7  lowkey:7  billed:7  keaton:7  socialist:7  disappointingly:7  evidently:7  compares:7  slate:7  allows:7  methods:7  bahston:7  puns:7  investigate:7  bizarrely:7  mud-and-guts:7  aghdashloo:7  screenings:7  abandon:7  dump:7  reminded:7  ozzy:7  painstakingly:7  bizarro:7  charmed:7  damned:7  asset:7  adulthood:7  education:7  ugliest-looking:7  dirtbikes:7  bought:7  spectre:7  dig:7  treats:7  cinematographic:7  duller:7  language:7  00100000:7  no-budget:7  over-cut:7  takakura:7  trio:7  non-stop:7  well-meaning:7  singing:7  offered:7  balanced-but-deep:7  baseball:7  submarine:7  discussing:7  twitter-famous:7  regime:7  bay:7  shining:7  overpowering:7  henson:7  impersonator:7  begins:7  shyamalan:7  54:7  bloated:7  ramping:7  operating:7  tense:7  flips:7  setpieces:7  monster:7  90:7  fan:7  2016:7  malick:7  later:7  mesmerizing:7  valentine:7  modernization:7  creators:7  wooden:7  relishes:7  photos:7  5:7  issue:7  boyd:7  91:7  aside:7  updated:7  stands:7  declares:7  happiness:7  landmark:7  eagle:7  titles:7  beguiling:7  promises:7  voodoo:7  primary:7  beloved:7  several:7  bottles:7  pulp:7  agency:7  classics:7  ruthless:7  exhausting:7  candidate:7  acted:7  mediocre:7  montage:7  duo:7  privilege:6  marguerite:6  scientist:6  confronts:6  kurzel:6  vulnerable:6  bug:6  holding:6  amazes:6  rousing:6  bones:6  hamm:6  di:6  davis:6  acid:6  diet:6  lunch:6  vulnerability:6  fighters:6  jean:6  rooted:6  self-loathing:6  racism:6  mike:6  sister:6  amongst:6  scuzzy:6  alfred:6  punishment:6  jokey:6  poisoned:6  twitch:6  bleakness:6  doctor:6  trigger:6  coon:6  rush:6  demon:6  killers:6  douglas:6  castle:6  fumbles:6  gradually:6  once-in-a-generation:6  weiner:6  dunkin:6  without:6  down-to-earth:6  consumerismthird:6  left-field:6  \n"
     ]
    }
   ],
   "source": [
    "near_negative = {}\n",
    "for word in top_100_negative:\n",
    "    sim = model.wv.most_similar(word, topn= 500)\n",
    "    for i in range(500):\n",
    "        synonym = sim[i][0]\n",
    "        #print(word)\n",
    "        if synonym in near_negative:\n",
    "            near_negative[synonym] += 1\n",
    "        else:\n",
    "            near_negative[synonym] = 1\n",
    "sorted_neg = {k: v for k, v in sorted(near_negative.items(), key=lambda item: item[1], reverse=True)}\n",
    "print(\"WORDS \\\"SIMILAR TO\\\" NEGATIVE WORDS:\")\n",
    "message = \"\"\n",
    "for key, value in list(sorted_neg.items())[:200]:\n",
    "    message += f\"{key}:{value}  \"\n",
    "print(message)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T04:37:51.719390500Z",
     "start_time": "2024-04-09T04:37:51.624617700Z"
    }
   },
   "id": "d52a46cda60b9342",
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "These results kinda suck, but improve some as i turn up the topn parameter. I imagine as the count values decrease, the less reliable the words get."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf8ba996781f2323"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T04:37:51.719390500Z",
     "start_time": "2024-04-09T04:37:51.717392Z"
    }
   },
   "id": "4854d1fb7a5b483f",
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
